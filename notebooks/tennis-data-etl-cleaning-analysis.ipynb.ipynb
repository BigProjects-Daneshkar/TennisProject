{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79cbb01a",
   "metadata": {},
   "source": [
    "# Data Reading Section:\n",
    "##### In this section, we will use the following codes, which will be explained below, to read the data we need from the main reference file and convert it to CSV format so that we can use it in the next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9223672",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d094c97",
   "metadata": {},
   "source": [
    "# âš ï¸ IMPORTANT â€” READ BEFORE RUNNING\n",
    "\n",
    "This notebook expects the raw dataset to be available **before execution**.  \n",
    "If the required ZIP file is not placed in the correct path, the ETL pipeline will fail or generate incomplete/duplicated outputs.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Required Action\n",
    "\n",
    "Please make sure the following file exists **before running the notebook**:\n",
    "\n",
    "..\\data\\raw\\tennis_data.zip\n",
    "\n",
    "\n",
    "> ðŸ“Œ The path is already configured inside the notebookâ€™s Python extraction script â€” do **not** change it unless necessary.\n",
    "\n",
    "If the ZIP file has a different name, please rename it or update the code accordingly.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f794cb9",
   "metadata": {},
   "source": [
    "# Part 1: Importing the required libraries, defining the paths, and creating the required directories if they do not exist.\n",
    "In this section, we import the libraries and items we need to use them later, and then we define the main paths, such as the main zip file path, the output file directory, and the temp directory, in a relational manner, to be included in the data folder of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e574b530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Ù…Ø³ÛŒØ± ÙØ¹Ù„ÛŒ: /Users/macbook/Downloads/Daneshkar/tennis project/TennisProject\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "os.chdir(\"..\") \n",
    "\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9be967c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, zipfile\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from io import BytesIO\n",
    "\n",
    "# Define paths\n",
    "main_zip = \"./data/raw/tennis_data.zip\"\n",
    "output_dir = \"./data/processed\"\n",
    "temp_dir = \"./data/raw/temp\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(temp_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969c20e4",
   "metadata": {},
   "source": [
    "# Part 2: Creating a CSV table generator function from Parquet files\n",
    "In this section, we have created a very useful function that, based on the keyword of the parquet category name that we give it, goes to the defined path of the main zip file and reads the parquets belonging to the specified tables and the data related to the specified columns from the zip files for each day. In addition to all this, we specify that the records of this table should be unique based on the unique data identifier or that this table can have multiple rows for each unique identifier. Our unique identifier is match_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9079ff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_table(table_keyword, needed_cols, output_name, dedup_on=\"match_id\"):\n",
    "    \"\"\"\n",
    "    table_keyword: like 'event_' or 'home_team_'\n",
    "    needed_cols: list of needed columns\n",
    "    output_name: name of output CSV file\n",
    "    dedup_on: unique column for deduplication (default is 'match_id')\n",
    "    \"\"\"\n",
    "    csv_path = os.path.join(output_dir, output_name)\n",
    "    if os.path.exists(csv_path):\n",
    "        os.remove(csv_path)\n",
    "\n",
    "    all_dfs = []\n",
    "    row_counter = 0\n",
    "\n",
    "    with zipfile.ZipFile(main_zip, \"r\") as main_zip_ref:\n",
    "        daily_zips = main_zip_ref.namelist()\n",
    "        print(f\"ðŸ“¦ Count of daily zips: {len(daily_zips)}\")\n",
    "\n",
    "        for i, daily_zip_name in enumerate(daily_zips, start=1):\n",
    "            print(f\"ðŸ”¹ ({i}/{len(daily_zips)}) processing {daily_zip_name} ...\")\n",
    "            main_zip_ref.extract(daily_zip_name, temp_dir)\n",
    "            daily_zip_path = os.path.join(temp_dir, daily_zip_name)\n",
    "\n",
    "            with zipfile.ZipFile(daily_zip_path, \"r\") as daily_zip_ref:\n",
    "                parquet_files = [f for f in daily_zip_ref.namelist() if f.endswith(\".parquet\") and table_keyword in f]\n",
    "                for f in parquet_files:\n",
    "                    with daily_zip_ref.open(f) as pf:\n",
    "                        table = pq.read_table(BytesIO(pf.read()))\n",
    "                        df = table.to_pandas()\n",
    "                        df = df[[c for c in needed_cols if c in df.columns]]\n",
    "                        df[\"date_source\"] = daily_zip_name.replace(\".zip\", \"\")\n",
    "                        all_dfs.append(df)\n",
    "                        row_counter += len(df)\n",
    "\n",
    "            os.remove(daily_zip_path)\n",
    "\n",
    "    if all_dfs:\n",
    "        df_all = pd.concat(all_dfs, ignore_index=True)\n",
    "        print(f\"âœ… Shape: {df_all.shape}\")\n",
    "        if dedup_on and dedup_on in df_all.columns:\n",
    "            df_all = df_all.drop_duplicates(subset=dedup_on)\n",
    "        else:\n",
    "            df_all = df_all.drop_duplicates()\n",
    "        print(f\"ðŸ§¹ after cleaning duplicated rows: {df_all.shape}\")\n",
    "\n",
    "        df_all.to_csv(csv_path, index=False)\n",
    "        print(f\"ðŸ’¾ Saved: {csv_path}\")\n",
    "        print(f\"ðŸ“Š Count of all rows: {len(df_all)}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ There is no file for {table_keyword}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97486bc8",
   "metadata": {},
   "source": [
    "# Part 3: Using the above cell function and creating CSVs of the tables required for analysis according to the columns required from them\n",
    "In this part, based on the initial analysis we had of the 17 questions in question and the data they required, we extracted a series of tables from a total of 15 tables and a series of their columns that were needed to analyze and answer the 17 questions we needed. Here, we want to extract them from the original raw zip file and convert them to CSV files so that we can use these files later in analyzing and answering the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "594441d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Count of daily zips: 60\n",
      "ðŸ”¹ (1/60) processing 20240205.zip ...\n",
      "ðŸ”¹ (2/60) processing 20240206.zip ...\n",
      "ðŸ”¹ (3/60) processing 20240207.zip ...\n",
      "ðŸ”¹ (4/60) processing 20240208.zip ...\n",
      "ðŸ”¹ (5/60) processing 20240209.zip ...\n",
      "ðŸ”¹ (6/60) processing 20240210.zip ...\n",
      "ðŸ”¹ (7/60) processing 20240211.zip ...\n",
      "ðŸ”¹ (8/60) processing 20240212.zip ...\n",
      "ðŸ”¹ (9/60) processing 20240213.zip ...\n",
      "ðŸ”¹ (10/60) processing 20240214.zip ...\n",
      "ðŸ”¹ (11/60) processing 20240215.zip ...\n",
      "ðŸ”¹ (12/60) processing 20240216.zip ...\n",
      "ðŸ”¹ (13/60) processing 20240217.zip ...\n",
      "ðŸ”¹ (14/60) processing 20240218.zip ...\n",
      "ðŸ”¹ (15/60) processing 20240219.zip ...\n",
      "ðŸ”¹ (16/60) processing 20240220.zip ...\n",
      "ðŸ”¹ (17/60) processing 20240221.zip ...\n",
      "ðŸ”¹ (18/60) processing 20240222.zip ...\n",
      "ðŸ”¹ (19/60) processing 20240223.zip ...\n",
      "ðŸ”¹ (20/60) processing 20240224.zip ...\n",
      "ðŸ”¹ (21/60) processing 20240225.zip ...\n",
      "ðŸ”¹ (22/60) processing 20240226.zip ...\n",
      "ðŸ”¹ (23/60) processing 20240227.zip ...\n",
      "ðŸ”¹ (24/60) processing 20240228.zip ...\n",
      "ðŸ”¹ (25/60) processing 20240229.zip ...\n",
      "ðŸ”¹ (26/60) processing 20240301.zip ...\n",
      "ðŸ”¹ (27/60) processing 20240302.zip ...\n",
      "ðŸ”¹ (28/60) processing 20240303.zip ...\n",
      "ðŸ”¹ (29/60) processing 20240304.zip ...\n",
      "ðŸ”¹ (30/60) processing 20240305.zip ...\n",
      "ðŸ”¹ (31/60) processing 20240306.zip ...\n",
      "ðŸ”¹ (32/60) processing 20240307.zip ...\n",
      "ðŸ”¹ (33/60) processing 20240308.zip ...\n",
      "ðŸ”¹ (34/60) processing 20240309.zip ...\n",
      "ðŸ”¹ (35/60) processing 20240310.zip ...\n",
      "ðŸ”¹ (36/60) processing 20240311.zip ...\n",
      "ðŸ”¹ (37/60) processing 20240312.zip ...\n",
      "ðŸ”¹ (38/60) processing 20240313.zip ...\n",
      "ðŸ”¹ (39/60) processing 20240314.zip ...\n",
      "ðŸ”¹ (40/60) processing 20240315.zip ...\n",
      "ðŸ”¹ (41/60) processing 20240316.zip ...\n",
      "ðŸ”¹ (42/60) processing 20240317.zip ...\n",
      "ðŸ”¹ (43/60) processing 20240318.zip ...\n",
      "ðŸ”¹ (44/60) processing 20240319.zip ...\n",
      "ðŸ”¹ (45/60) processing 20240320.zip ...\n",
      "ðŸ”¹ (46/60) processing 20240321.zip ...\n",
      "ðŸ”¹ (47/60) processing 20240322.zip ...\n",
      "ðŸ”¹ (48/60) processing 20240323.zip ...\n",
      "ðŸ”¹ (49/60) processing 20240324.zip ...\n",
      "ðŸ”¹ (50/60) processing 20240325.zip ...\n",
      "ðŸ”¹ (51/60) processing 20240326.zip ...\n",
      "ðŸ”¹ (52/60) processing 20240327.zip ...\n",
      "ðŸ”¹ (53/60) processing 20240328.zip ...\n",
      "ðŸ”¹ (54/60) processing 20240329.zip ...\n",
      "ðŸ”¹ (55/60) processing 20240330.zip ...\n",
      "ðŸ”¹ (56/60) processing 20240331.zip ...\n",
      "ðŸ”¹ (57/60) processing 20240201.zip ...\n",
      "ðŸ”¹ (58/60) processing 20240202.zip ...\n",
      "ðŸ”¹ (59/60) processing 20240203.zip ...\n",
      "ðŸ”¹ (60/60) processing 20240204.zip ...\n",
      "âœ… Shape: (35053, 7)\n",
      "ðŸ§¹ after cleaning duplicated rows: (16873, 7)\n",
      "ðŸ’¾ Saved: ./data/processed/event.csv\n",
      "ðŸ“Š Count of all rows: 16873\n",
      "ðŸ“¦ Count of daily zips: 60\n",
      "ðŸ”¹ (1/60) processing 20240205.zip ...\n",
      "ðŸ”¹ (2/60) processing 20240206.zip ...\n",
      "ðŸ”¹ (3/60) processing 20240207.zip ...\n",
      "ðŸ”¹ (4/60) processing 20240208.zip ...\n",
      "ðŸ”¹ (5/60) processing 20240209.zip ...\n",
      "ðŸ”¹ (6/60) processing 20240210.zip ...\n",
      "ðŸ”¹ (7/60) processing 20240211.zip ...\n",
      "ðŸ”¹ (8/60) processing 20240212.zip ...\n",
      "ðŸ”¹ (9/60) processing 20240213.zip ...\n",
      "ðŸ”¹ (10/60) processing 20240214.zip ...\n",
      "ðŸ”¹ (11/60) processing 20240215.zip ...\n",
      "ðŸ”¹ (12/60) processing 20240216.zip ...\n",
      "ðŸ”¹ (13/60) processing 20240217.zip ...\n",
      "ðŸ”¹ (14/60) processing 20240218.zip ...\n",
      "ðŸ”¹ (15/60) processing 20240219.zip ...\n",
      "ðŸ”¹ (16/60) processing 20240220.zip ...\n",
      "ðŸ”¹ (17/60) processing 20240221.zip ...\n",
      "ðŸ”¹ (18/60) processing 20240222.zip ...\n",
      "ðŸ”¹ (19/60) processing 20240223.zip ...\n",
      "ðŸ”¹ (20/60) processing 20240224.zip ...\n",
      "ðŸ”¹ (21/60) processing 20240225.zip ...\n",
      "ðŸ”¹ (22/60) processing 20240226.zip ...\n",
      "ðŸ”¹ (23/60) processing 20240227.zip ...\n",
      "ðŸ”¹ (24/60) processing 20240228.zip ...\n",
      "ðŸ”¹ (25/60) processing 20240229.zip ...\n",
      "ðŸ”¹ (26/60) processing 20240301.zip ...\n",
      "ðŸ”¹ (27/60) processing 20240302.zip ...\n",
      "ðŸ”¹ (28/60) processing 20240303.zip ...\n",
      "ðŸ”¹ (29/60) processing 20240304.zip ...\n",
      "ðŸ”¹ (30/60) processing 20240305.zip ...\n",
      "ðŸ”¹ (31/60) processing 20240306.zip ...\n",
      "ðŸ”¹ (32/60) processing 20240307.zip ...\n",
      "ðŸ”¹ (33/60) processing 20240308.zip ...\n",
      "ðŸ”¹ (34/60) processing 20240309.zip ...\n",
      "ðŸ”¹ (35/60) processing 20240310.zip ...\n",
      "ðŸ”¹ (36/60) processing 20240311.zip ...\n",
      "ðŸ”¹ (37/60) processing 20240312.zip ...\n",
      "ðŸ”¹ (38/60) processing 20240313.zip ...\n",
      "ðŸ”¹ (39/60) processing 20240314.zip ...\n",
      "ðŸ”¹ (40/60) processing 20240315.zip ...\n",
      "ðŸ”¹ (41/60) processing 20240316.zip ...\n",
      "ðŸ”¹ (42/60) processing 20240317.zip ...\n",
      "ðŸ”¹ (43/60) processing 20240318.zip ...\n",
      "ðŸ”¹ (44/60) processing 20240319.zip ...\n",
      "ðŸ”¹ (45/60) processing 20240320.zip ...\n",
      "ðŸ”¹ (46/60) processing 20240321.zip ...\n",
      "ðŸ”¹ (47/60) processing 20240322.zip ...\n",
      "ðŸ”¹ (48/60) processing 20240323.zip ...\n",
      "ðŸ”¹ (49/60) processing 20240324.zip ...\n",
      "ðŸ”¹ (50/60) processing 20240325.zip ...\n",
      "ðŸ”¹ (51/60) processing 20240326.zip ...\n",
      "ðŸ”¹ (52/60) processing 20240327.zip ...\n",
      "ðŸ”¹ (53/60) processing 20240328.zip ...\n",
      "ðŸ”¹ (54/60) processing 20240329.zip ...\n",
      "ðŸ”¹ (55/60) processing 20240330.zip ...\n",
      "ðŸ”¹ (56/60) processing 20240331.zip ...\n",
      "ðŸ”¹ (57/60) processing 20240201.zip ...\n",
      "ðŸ”¹ (58/60) processing 20240202.zip ...\n",
      "ðŸ”¹ (59/60) processing 20240203.zip ...\n",
      "ðŸ”¹ (60/60) processing 20240204.zip ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7_/v4rsdhms583_wn2td78pfgjm0000gn/T/ipykernel_1556/366242421.py:38: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_all = pd.concat(all_dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Shape: (60774, 10)\n",
      "ðŸ§¹ after cleaning duplicated rows: (16873, 10)\n",
      "ðŸ’¾ Saved: ./data/processed/home_team.csv\n",
      "ðŸ“Š Count of all rows: 16873\n",
      "ðŸ“¦ Count of daily zips: 60\n",
      "ðŸ”¹ (1/60) processing 20240205.zip ...\n",
      "ðŸ”¹ (2/60) processing 20240206.zip ...\n",
      "ðŸ”¹ (3/60) processing 20240207.zip ...\n",
      "ðŸ”¹ (4/60) processing 20240208.zip ...\n",
      "ðŸ”¹ (5/60) processing 20240209.zip ...\n",
      "ðŸ”¹ (6/60) processing 20240210.zip ...\n",
      "ðŸ”¹ (7/60) processing 20240211.zip ...\n",
      "ðŸ”¹ (8/60) processing 20240212.zip ...\n",
      "ðŸ”¹ (9/60) processing 20240213.zip ...\n",
      "ðŸ”¹ (10/60) processing 20240214.zip ...\n",
      "ðŸ”¹ (11/60) processing 20240215.zip ...\n",
      "ðŸ”¹ (12/60) processing 20240216.zip ...\n",
      "ðŸ”¹ (13/60) processing 20240217.zip ...\n",
      "ðŸ”¹ (14/60) processing 20240218.zip ...\n",
      "ðŸ”¹ (15/60) processing 20240219.zip ...\n",
      "ðŸ”¹ (16/60) processing 20240220.zip ...\n",
      "ðŸ”¹ (17/60) processing 20240221.zip ...\n",
      "ðŸ”¹ (18/60) processing 20240222.zip ...\n",
      "ðŸ”¹ (19/60) processing 20240223.zip ...\n",
      "ðŸ”¹ (20/60) processing 20240224.zip ...\n",
      "ðŸ”¹ (21/60) processing 20240225.zip ...\n",
      "ðŸ”¹ (22/60) processing 20240226.zip ...\n",
      "ðŸ”¹ (23/60) processing 20240227.zip ...\n",
      "ðŸ”¹ (24/60) processing 20240228.zip ...\n",
      "ðŸ”¹ (25/60) processing 20240229.zip ...\n",
      "ðŸ”¹ (26/60) processing 20240301.zip ...\n",
      "ðŸ”¹ (27/60) processing 20240302.zip ...\n",
      "ðŸ”¹ (28/60) processing 20240303.zip ...\n",
      "ðŸ”¹ (29/60) processing 20240304.zip ...\n",
      "ðŸ”¹ (30/60) processing 20240305.zip ...\n",
      "ðŸ”¹ (31/60) processing 20240306.zip ...\n",
      "ðŸ”¹ (32/60) processing 20240307.zip ...\n",
      "ðŸ”¹ (33/60) processing 20240308.zip ...\n",
      "ðŸ”¹ (34/60) processing 20240309.zip ...\n",
      "ðŸ”¹ (35/60) processing 20240310.zip ...\n",
      "ðŸ”¹ (36/60) processing 20240311.zip ...\n",
      "ðŸ”¹ (37/60) processing 20240312.zip ...\n",
      "ðŸ”¹ (38/60) processing 20240313.zip ...\n",
      "ðŸ”¹ (39/60) processing 20240314.zip ...\n",
      "ðŸ”¹ (40/60) processing 20240315.zip ...\n",
      "ðŸ”¹ (41/60) processing 20240316.zip ...\n",
      "ðŸ”¹ (42/60) processing 20240317.zip ...\n",
      "ðŸ”¹ (43/60) processing 20240318.zip ...\n",
      "ðŸ”¹ (44/60) processing 20240319.zip ...\n",
      "ðŸ”¹ (45/60) processing 20240320.zip ...\n",
      "ðŸ”¹ (46/60) processing 20240321.zip ...\n",
      "ðŸ”¹ (47/60) processing 20240322.zip ...\n",
      "ðŸ”¹ (48/60) processing 20240323.zip ...\n",
      "ðŸ”¹ (49/60) processing 20240324.zip ...\n",
      "ðŸ”¹ (50/60) processing 20240325.zip ...\n",
      "ðŸ”¹ (51/60) processing 20240326.zip ...\n",
      "ðŸ”¹ (52/60) processing 20240327.zip ...\n",
      "ðŸ”¹ (53/60) processing 20240328.zip ...\n",
      "ðŸ”¹ (54/60) processing 20240329.zip ...\n",
      "ðŸ”¹ (55/60) processing 20240330.zip ...\n",
      "ðŸ”¹ (56/60) processing 20240331.zip ...\n",
      "ðŸ”¹ (57/60) processing 20240201.zip ...\n",
      "ðŸ”¹ (58/60) processing 20240202.zip ...\n",
      "ðŸ”¹ (59/60) processing 20240203.zip ...\n",
      "ðŸ”¹ (60/60) processing 20240204.zip ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7_/v4rsdhms583_wn2td78pfgjm0000gn/T/ipykernel_1556/366242421.py:38: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_all = pd.concat(all_dfs, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Shape: (59256, 10)\n",
      "ðŸ§¹ after cleaning duplicated rows: (16873, 10)\n",
      "ðŸ’¾ Saved: ./data/processed/away_team.csv\n",
      "ðŸ“Š Count of all rows: 16873\n",
      "ðŸ“¦ Count of daily zips: 60\n",
      "ðŸ”¹ (1/60) processing 20240205.zip ...\n",
      "ðŸ”¹ (2/60) processing 20240206.zip ...\n",
      "ðŸ”¹ (3/60) processing 20240207.zip ...\n",
      "ðŸ”¹ (4/60) processing 20240208.zip ...\n",
      "ðŸ”¹ (5/60) processing 20240209.zip ...\n",
      "ðŸ”¹ (6/60) processing 20240210.zip ...\n",
      "ðŸ”¹ (7/60) processing 20240211.zip ...\n",
      "ðŸ”¹ (8/60) processing 20240212.zip ...\n",
      "ðŸ”¹ (9/60) processing 20240213.zip ...\n",
      "ðŸ”¹ (10/60) processing 20240214.zip ...\n",
      "ðŸ”¹ (11/60) processing 20240215.zip ...\n",
      "ðŸ”¹ (12/60) processing 20240216.zip ...\n",
      "ðŸ”¹ (13/60) processing 20240217.zip ...\n",
      "ðŸ”¹ (14/60) processing 20240218.zip ...\n",
      "ðŸ”¹ (15/60) processing 20240219.zip ...\n",
      "ðŸ”¹ (16/60) processing 20240220.zip ...\n",
      "ðŸ”¹ (17/60) processing 20240221.zip ...\n",
      "ðŸ”¹ (18/60) processing 20240222.zip ...\n",
      "ðŸ”¹ (19/60) processing 20240223.zip ...\n",
      "ðŸ”¹ (20/60) processing 20240224.zip ...\n",
      "ðŸ”¹ (21/60) processing 20240225.zip ...\n",
      "ðŸ”¹ (22/60) processing 20240226.zip ...\n",
      "ðŸ”¹ (23/60) processing 20240227.zip ...\n",
      "ðŸ”¹ (24/60) processing 20240228.zip ...\n",
      "ðŸ”¹ (25/60) processing 20240229.zip ...\n",
      "ðŸ”¹ (26/60) processing 20240301.zip ...\n",
      "ðŸ”¹ (27/60) processing 20240302.zip ...\n",
      "ðŸ”¹ (28/60) processing 20240303.zip ...\n",
      "ðŸ”¹ (29/60) processing 20240304.zip ...\n",
      "ðŸ”¹ (30/60) processing 20240305.zip ...\n",
      "ðŸ”¹ (31/60) processing 20240306.zip ...\n",
      "ðŸ”¹ (32/60) processing 20240307.zip ...\n",
      "ðŸ”¹ (33/60) processing 20240308.zip ...\n",
      "ðŸ”¹ (34/60) processing 20240309.zip ...\n",
      "ðŸ”¹ (35/60) processing 20240310.zip ...\n",
      "ðŸ”¹ (36/60) processing 20240311.zip ...\n",
      "ðŸ”¹ (37/60) processing 20240312.zip ...\n",
      "ðŸ”¹ (38/60) processing 20240313.zip ...\n",
      "ðŸ”¹ (39/60) processing 20240314.zip ...\n",
      "ðŸ”¹ (40/60) processing 20240315.zip ...\n",
      "ðŸ”¹ (41/60) processing 20240316.zip ...\n",
      "ðŸ”¹ (42/60) processing 20240317.zip ...\n",
      "ðŸ”¹ (43/60) processing 20240318.zip ...\n",
      "ðŸ”¹ (44/60) processing 20240319.zip ...\n",
      "ðŸ”¹ (45/60) processing 20240320.zip ...\n",
      "ðŸ”¹ (46/60) processing 20240321.zip ...\n",
      "ðŸ”¹ (47/60) processing 20240322.zip ...\n",
      "ðŸ”¹ (48/60) processing 20240323.zip ...\n",
      "ðŸ”¹ (49/60) processing 20240324.zip ...\n",
      "ðŸ”¹ (50/60) processing 20240325.zip ...\n",
      "ðŸ”¹ (51/60) processing 20240326.zip ...\n",
      "ðŸ”¹ (52/60) processing 20240327.zip ...\n",
      "ðŸ”¹ (53/60) processing 20240328.zip ...\n",
      "ðŸ”¹ (54/60) processing 20240329.zip ...\n",
      "ðŸ”¹ (55/60) processing 20240330.zip ...\n",
      "ðŸ”¹ (56/60) processing 20240331.zip ...\n",
      "ðŸ”¹ (57/60) processing 20240201.zip ...\n",
      "ðŸ”¹ (58/60) processing 20240202.zip ...\n",
      "ðŸ”¹ (59/60) processing 20240203.zip ...\n",
      "ðŸ”¹ (60/60) processing 20240204.zip ...\n",
      "âœ… Shape: (35671, 6)\n",
      "ðŸ§¹ after cleaning duplicated rows: (16873, 6)\n",
      "ðŸ’¾ Saved: ./data/processed/tournament.csv\n",
      "ðŸ“Š Count of all rows: 16873\n",
      "ðŸ“¦ Count of daily zips: 60\n",
      "ðŸ”¹ (1/60) processing 20240205.zip ...\n",
      "ðŸ”¹ (2/60) processing 20240206.zip ...\n",
      "ðŸ”¹ (3/60) processing 20240207.zip ...\n",
      "ðŸ”¹ (4/60) processing 20240208.zip ...\n",
      "ðŸ”¹ (5/60) processing 20240209.zip ...\n",
      "ðŸ”¹ (6/60) processing 20240210.zip ...\n",
      "ðŸ”¹ (7/60) processing 20240211.zip ...\n",
      "ðŸ”¹ (8/60) processing 20240212.zip ...\n",
      "ðŸ”¹ (9/60) processing 20240213.zip ...\n",
      "ðŸ”¹ (10/60) processing 20240214.zip ...\n",
      "ðŸ”¹ (11/60) processing 20240215.zip ...\n",
      "ðŸ”¹ (12/60) processing 20240216.zip ...\n",
      "ðŸ”¹ (13/60) processing 20240217.zip ...\n",
      "ðŸ”¹ (14/60) processing 20240218.zip ...\n",
      "ðŸ”¹ (15/60) processing 20240219.zip ...\n",
      "ðŸ”¹ (16/60) processing 20240220.zip ...\n",
      "ðŸ”¹ (17/60) processing 20240221.zip ...\n",
      "ðŸ”¹ (18/60) processing 20240222.zip ...\n",
      "ðŸ”¹ (19/60) processing 20240223.zip ...\n",
      "ðŸ”¹ (20/60) processing 20240224.zip ...\n",
      "ðŸ”¹ (21/60) processing 20240225.zip ...\n",
      "ðŸ”¹ (22/60) processing 20240226.zip ...\n",
      "ðŸ”¹ (23/60) processing 20240227.zip ...\n",
      "ðŸ”¹ (24/60) processing 20240228.zip ...\n",
      "ðŸ”¹ (25/60) processing 20240229.zip ...\n",
      "ðŸ”¹ (26/60) processing 20240301.zip ...\n",
      "ðŸ”¹ (27/60) processing 20240302.zip ...\n",
      "ðŸ”¹ (28/60) processing 20240303.zip ...\n",
      "ðŸ”¹ (29/60) processing 20240304.zip ...\n",
      "ðŸ”¹ (30/60) processing 20240305.zip ...\n",
      "ðŸ”¹ (31/60) processing 20240306.zip ...\n",
      "ðŸ”¹ (32/60) processing 20240307.zip ...\n",
      "ðŸ”¹ (33/60) processing 20240308.zip ...\n",
      "ðŸ”¹ (34/60) processing 20240309.zip ...\n",
      "ðŸ”¹ (35/60) processing 20240310.zip ...\n",
      "ðŸ”¹ (36/60) processing 20240311.zip ...\n",
      "ðŸ”¹ (37/60) processing 20240312.zip ...\n",
      "ðŸ”¹ (38/60) processing 20240313.zip ...\n",
      "ðŸ”¹ (39/60) processing 20240314.zip ...\n",
      "ðŸ”¹ (40/60) processing 20240315.zip ...\n",
      "ðŸ”¹ (41/60) processing 20240316.zip ...\n",
      "ðŸ”¹ (42/60) processing 20240317.zip ...\n",
      "ðŸ”¹ (43/60) processing 20240318.zip ...\n",
      "ðŸ”¹ (44/60) processing 20240319.zip ...\n",
      "ðŸ”¹ (45/60) processing 20240320.zip ...\n",
      "ðŸ”¹ (46/60) processing 20240321.zip ...\n",
      "ðŸ”¹ (47/60) processing 20240322.zip ...\n",
      "ðŸ”¹ (48/60) processing 20240323.zip ...\n",
      "ðŸ”¹ (49/60) processing 20240324.zip ...\n",
      "ðŸ”¹ (50/60) processing 20240325.zip ...\n",
      "ðŸ”¹ (51/60) processing 20240326.zip ...\n",
      "ðŸ”¹ (52/60) processing 20240327.zip ...\n",
      "ðŸ”¹ (53/60) processing 20240328.zip ...\n",
      "ðŸ”¹ (54/60) processing 20240329.zip ...\n",
      "ðŸ”¹ (55/60) processing 20240330.zip ...\n",
      "ðŸ”¹ (56/60) processing 20240331.zip ...\n",
      "ðŸ”¹ (57/60) processing 20240201.zip ...\n",
      "ðŸ”¹ (58/60) processing 20240202.zip ...\n",
      "ðŸ”¹ (59/60) processing 20240203.zip ...\n",
      "ðŸ”¹ (60/60) processing 20240204.zip ...\n",
      "âœ… Shape: (35671, 8)\n",
      "ðŸ§¹ after cleaning duplicated rows: (16873, 8)\n",
      "ðŸ’¾ Saved: ./data/processed/time.csv\n",
      "ðŸ“Š Count of all rows: 16873\n",
      "ðŸ“¦ Count of daily zips: 60\n",
      "ðŸ”¹ (1/60) processing 20240205.zip ...\n",
      "ðŸ”¹ (2/60) processing 20240206.zip ...\n",
      "ðŸ”¹ (3/60) processing 20240207.zip ...\n",
      "ðŸ”¹ (4/60) processing 20240208.zip ...\n",
      "ðŸ”¹ (5/60) processing 20240209.zip ...\n",
      "ðŸ”¹ (6/60) processing 20240210.zip ...\n",
      "ðŸ”¹ (7/60) processing 20240211.zip ...\n",
      "ðŸ”¹ (8/60) processing 20240212.zip ...\n",
      "ðŸ”¹ (9/60) processing 20240213.zip ...\n",
      "ðŸ”¹ (10/60) processing 20240214.zip ...\n",
      "ðŸ”¹ (11/60) processing 20240215.zip ...\n",
      "ðŸ”¹ (12/60) processing 20240216.zip ...\n",
      "ðŸ”¹ (13/60) processing 20240217.zip ...\n",
      "ðŸ”¹ (14/60) processing 20240218.zip ...\n",
      "ðŸ”¹ (15/60) processing 20240219.zip ...\n",
      "ðŸ”¹ (16/60) processing 20240220.zip ...\n",
      "ðŸ”¹ (17/60) processing 20240221.zip ...\n",
      "ðŸ”¹ (18/60) processing 20240222.zip ...\n",
      "ðŸ”¹ (19/60) processing 20240223.zip ...\n",
      "ðŸ”¹ (20/60) processing 20240224.zip ...\n",
      "ðŸ”¹ (21/60) processing 20240225.zip ...\n",
      "ðŸ”¹ (22/60) processing 20240226.zip ...\n",
      "ðŸ”¹ (23/60) processing 20240227.zip ...\n",
      "ðŸ”¹ (24/60) processing 20240228.zip ...\n",
      "ðŸ”¹ (25/60) processing 20240229.zip ...\n",
      "ðŸ”¹ (26/60) processing 20240301.zip ...\n",
      "ðŸ”¹ (27/60) processing 20240302.zip ...\n",
      "ðŸ”¹ (28/60) processing 20240303.zip ...\n",
      "ðŸ”¹ (29/60) processing 20240304.zip ...\n",
      "ðŸ”¹ (30/60) processing 20240305.zip ...\n",
      "ðŸ”¹ (31/60) processing 20240306.zip ...\n",
      "ðŸ”¹ (32/60) processing 20240307.zip ...\n",
      "ðŸ”¹ (33/60) processing 20240308.zip ...\n",
      "ðŸ”¹ (34/60) processing 20240309.zip ...\n",
      "ðŸ”¹ (35/60) processing 20240310.zip ...\n",
      "ðŸ”¹ (36/60) processing 20240311.zip ...\n",
      "ðŸ”¹ (37/60) processing 20240312.zip ...\n",
      "ðŸ”¹ (38/60) processing 20240313.zip ...\n",
      "ðŸ”¹ (39/60) processing 20240314.zip ...\n",
      "ðŸ”¹ (40/60) processing 20240315.zip ...\n",
      "ðŸ”¹ (41/60) processing 20240316.zip ...\n",
      "ðŸ”¹ (42/60) processing 20240317.zip ...\n",
      "ðŸ”¹ (43/60) processing 20240318.zip ...\n",
      "ðŸ”¹ (44/60) processing 20240319.zip ...\n",
      "ðŸ”¹ (45/60) processing 20240320.zip ...\n",
      "ðŸ”¹ (46/60) processing 20240321.zip ...\n",
      "ðŸ”¹ (47/60) processing 20240322.zip ...\n",
      "ðŸ”¹ (48/60) processing 20240323.zip ...\n",
      "ðŸ”¹ (49/60) processing 20240324.zip ...\n",
      "ðŸ”¹ (50/60) processing 20240325.zip ...\n",
      "ðŸ”¹ (51/60) processing 20240326.zip ...\n",
      "ðŸ”¹ (52/60) processing 20240327.zip ...\n",
      "ðŸ”¹ (53/60) processing 20240328.zip ...\n",
      "ðŸ”¹ (54/60) processing 20240329.zip ...\n",
      "ðŸ”¹ (55/60) processing 20240330.zip ...\n",
      "ðŸ”¹ (56/60) processing 20240331.zip ...\n",
      "ðŸ”¹ (57/60) processing 20240201.zip ...\n",
      "ðŸ”¹ (58/60) processing 20240202.zip ...\n",
      "ðŸ”¹ (59/60) processing 20240203.zip ...\n",
      "ðŸ”¹ (60/60) processing 20240204.zip ...\n",
      "âœ… Shape: (1358234, 5)\n",
      "ðŸ§¹ after cleaning duplicated rows: (1238888, 5)\n",
      "ðŸ’¾ Saved: ./data/processed/statistics.csv\n",
      "ðŸ“Š Count of all rows: 1238888\n",
      "ðŸ“¦ Count of daily zips: 60\n",
      "ðŸ”¹ (1/60) processing 20240205.zip ...\n",
      "ðŸ”¹ (2/60) processing 20240206.zip ...\n",
      "ðŸ”¹ (3/60) processing 20240207.zip ...\n",
      "ðŸ”¹ (4/60) processing 20240208.zip ...\n",
      "ðŸ”¹ (5/60) processing 20240209.zip ...\n",
      "ðŸ”¹ (6/60) processing 20240210.zip ...\n",
      "ðŸ”¹ (7/60) processing 20240211.zip ...\n",
      "ðŸ”¹ (8/60) processing 20240212.zip ...\n",
      "ðŸ”¹ (9/60) processing 20240213.zip ...\n",
      "ðŸ”¹ (10/60) processing 20240214.zip ...\n",
      "ðŸ”¹ (11/60) processing 20240215.zip ...\n",
      "ðŸ”¹ (12/60) processing 20240216.zip ...\n",
      "ðŸ”¹ (13/60) processing 20240217.zip ...\n",
      "ðŸ”¹ (14/60) processing 20240218.zip ...\n",
      "ðŸ”¹ (15/60) processing 20240219.zip ...\n",
      "ðŸ”¹ (16/60) processing 20240220.zip ...\n",
      "ðŸ”¹ (17/60) processing 20240221.zip ...\n",
      "ðŸ”¹ (18/60) processing 20240222.zip ...\n",
      "ðŸ”¹ (19/60) processing 20240223.zip ...\n",
      "ðŸ”¹ (20/60) processing 20240224.zip ...\n",
      "ðŸ”¹ (21/60) processing 20240225.zip ...\n",
      "ðŸ”¹ (22/60) processing 20240226.zip ...\n",
      "ðŸ”¹ (23/60) processing 20240227.zip ...\n",
      "ðŸ”¹ (24/60) processing 20240228.zip ...\n",
      "ðŸ”¹ (25/60) processing 20240229.zip ...\n",
      "ðŸ”¹ (26/60) processing 20240301.zip ...\n",
      "ðŸ”¹ (27/60) processing 20240302.zip ...\n",
      "ðŸ”¹ (28/60) processing 20240303.zip ...\n",
      "ðŸ”¹ (29/60) processing 20240304.zip ...\n",
      "ðŸ”¹ (30/60) processing 20240305.zip ...\n",
      "ðŸ”¹ (31/60) processing 20240306.zip ...\n",
      "ðŸ”¹ (32/60) processing 20240307.zip ...\n",
      "ðŸ”¹ (33/60) processing 20240308.zip ...\n",
      "ðŸ”¹ (34/60) processing 20240309.zip ...\n",
      "ðŸ”¹ (35/60) processing 20240310.zip ...\n",
      "ðŸ”¹ (36/60) processing 20240311.zip ...\n",
      "ðŸ”¹ (37/60) processing 20240312.zip ...\n",
      "ðŸ”¹ (38/60) processing 20240313.zip ...\n",
      "ðŸ”¹ (39/60) processing 20240314.zip ...\n",
      "ðŸ”¹ (40/60) processing 20240315.zip ...\n",
      "ðŸ”¹ (41/60) processing 20240316.zip ...\n",
      "ðŸ”¹ (42/60) processing 20240317.zip ...\n",
      "ðŸ”¹ (43/60) processing 20240318.zip ...\n",
      "ðŸ”¹ (44/60) processing 20240319.zip ...\n",
      "ðŸ”¹ (45/60) processing 20240320.zip ...\n",
      "ðŸ”¹ (46/60) processing 20240321.zip ...\n",
      "ðŸ”¹ (47/60) processing 20240322.zip ...\n",
      "ðŸ”¹ (48/60) processing 20240323.zip ...\n",
      "ðŸ”¹ (49/60) processing 20240324.zip ...\n",
      "ðŸ”¹ (50/60) processing 20240325.zip ...\n",
      "ðŸ”¹ (51/60) processing 20240326.zip ...\n",
      "ðŸ”¹ (52/60) processing 20240327.zip ...\n",
      "ðŸ”¹ (53/60) processing 20240328.zip ...\n",
      "ðŸ”¹ (54/60) processing 20240329.zip ...\n",
      "ðŸ”¹ (55/60) processing 20240330.zip ...\n",
      "ðŸ”¹ (56/60) processing 20240331.zip ...\n",
      "ðŸ”¹ (57/60) processing 20240201.zip ...\n",
      "ðŸ”¹ (58/60) processing 20240202.zip ...\n",
      "ðŸ”¹ (59/60) processing 20240203.zip ...\n",
      "ðŸ”¹ (60/60) processing 20240204.zip ...\n",
      "âœ… Shape: (469677, 6)\n",
      "ðŸ§¹ after cleaning duplicated rows: (469677, 6)\n",
      "ðŸ’¾ Saved: ./data/processed/power.csv\n",
      "ðŸ“Š Count of all rows: 469677\n",
      "ðŸ“¦ Count of daily zips: 60\n",
      "ðŸ”¹ (1/60) processing 20240205.zip ...\n",
      "ðŸ”¹ (2/60) processing 20240206.zip ...\n",
      "ðŸ”¹ (3/60) processing 20240207.zip ...\n",
      "ðŸ”¹ (4/60) processing 20240208.zip ...\n",
      "ðŸ”¹ (5/60) processing 20240209.zip ...\n",
      "ðŸ”¹ (6/60) processing 20240210.zip ...\n",
      "ðŸ”¹ (7/60) processing 20240211.zip ...\n",
      "ðŸ”¹ (8/60) processing 20240212.zip ...\n",
      "ðŸ”¹ (9/60) processing 20240213.zip ...\n",
      "ðŸ”¹ (10/60) processing 20240214.zip ...\n",
      "ðŸ”¹ (11/60) processing 20240215.zip ...\n",
      "ðŸ”¹ (12/60) processing 20240216.zip ...\n",
      "ðŸ”¹ (13/60) processing 20240217.zip ...\n",
      "ðŸ”¹ (14/60) processing 20240218.zip ...\n",
      "ðŸ”¹ (15/60) processing 20240219.zip ...\n",
      "ðŸ”¹ (16/60) processing 20240220.zip ...\n",
      "ðŸ”¹ (17/60) processing 20240221.zip ...\n",
      "ðŸ”¹ (18/60) processing 20240222.zip ...\n",
      "ðŸ”¹ (19/60) processing 20240223.zip ...\n",
      "ðŸ”¹ (20/60) processing 20240224.zip ...\n",
      "ðŸ”¹ (21/60) processing 20240225.zip ...\n",
      "ðŸ”¹ (22/60) processing 20240226.zip ...\n",
      "ðŸ”¹ (23/60) processing 20240227.zip ...\n",
      "ðŸ”¹ (24/60) processing 20240228.zip ...\n",
      "ðŸ”¹ (25/60) processing 20240229.zip ...\n",
      "ðŸ”¹ (26/60) processing 20240301.zip ...\n",
      "ðŸ”¹ (27/60) processing 20240302.zip ...\n",
      "ðŸ”¹ (28/60) processing 20240303.zip ...\n",
      "ðŸ”¹ (29/60) processing 20240304.zip ...\n",
      "ðŸ”¹ (30/60) processing 20240305.zip ...\n",
      "ðŸ”¹ (31/60) processing 20240306.zip ...\n",
      "ðŸ”¹ (32/60) processing 20240307.zip ...\n",
      "ðŸ”¹ (33/60) processing 20240308.zip ...\n",
      "ðŸ”¹ (34/60) processing 20240309.zip ...\n",
      "ðŸ”¹ (35/60) processing 20240310.zip ...\n",
      "ðŸ”¹ (36/60) processing 20240311.zip ...\n",
      "ðŸ”¹ (37/60) processing 20240312.zip ...\n",
      "ðŸ”¹ (38/60) processing 20240313.zip ...\n",
      "ðŸ”¹ (39/60) processing 20240314.zip ...\n",
      "ðŸ”¹ (40/60) processing 20240315.zip ...\n",
      "ðŸ”¹ (41/60) processing 20240316.zip ...\n",
      "ðŸ”¹ (42/60) processing 20240317.zip ...\n",
      "ðŸ”¹ (43/60) processing 20240318.zip ...\n",
      "ðŸ”¹ (44/60) processing 20240319.zip ...\n",
      "ðŸ”¹ (45/60) processing 20240320.zip ...\n",
      "ðŸ”¹ (46/60) processing 20240321.zip ...\n",
      "ðŸ”¹ (47/60) processing 20240322.zip ...\n",
      "ðŸ”¹ (48/60) processing 20240323.zip ...\n",
      "ðŸ”¹ (49/60) processing 20240324.zip ...\n",
      "ðŸ”¹ (50/60) processing 20240325.zip ...\n",
      "ðŸ”¹ (51/60) processing 20240326.zip ...\n",
      "ðŸ”¹ (52/60) processing 20240327.zip ...\n",
      "ðŸ”¹ (53/60) processing 20240328.zip ...\n",
      "ðŸ”¹ (54/60) processing 20240329.zip ...\n",
      "ðŸ”¹ (55/60) processing 20240330.zip ...\n",
      "ðŸ”¹ (56/60) processing 20240331.zip ...\n",
      "ðŸ”¹ (57/60) processing 20240201.zip ...\n",
      "ðŸ”¹ (58/60) processing 20240202.zip ...\n",
      "ðŸ”¹ (59/60) processing 20240203.zip ...\n",
      "ðŸ”¹ (60/60) processing 20240204.zip ...\n",
      "âœ… Shape: (2549369, 7)\n",
      "ðŸ§¹ after cleaning duplicated rows: (2549369, 7)\n",
      "ðŸ’¾ Saved: ./data/processed/pbp.csv\n",
      "ðŸ“Š Count of all rows: 2549369\n"
     ]
    }
   ],
   "source": [
    "build_table(\n",
    "    table_keyword=\"event_\",\n",
    "    needed_cols=[\"match_id\", \"first_to_serve\", \"winner_code\", \"default_period_count\", \"start_datetime\", \"match_slug\"],\n",
    "    output_name=\"event.csv\",\n",
    "    dedup_on=\"match_id\"\n",
    ")\n",
    "\n",
    "build_table(\n",
    "    table_keyword=\"home_team_\",\n",
    "    needed_cols=[\"match_id\", \"player_id\", \"full_name\", \"gender\", \"height\", \"weight\", \"plays\", \"current_rank\", \"country\"],\n",
    "    output_name=\"home_team.csv\",\n",
    "    dedup_on=\"match_id\"\n",
    ")\n",
    "\n",
    "build_table(\n",
    "    table_keyword=\"away_team_\",\n",
    "    needed_cols=[\"match_id\", \"player_id\", \"full_name\", \"gender\", \"height\", \"weight\", \"plays\", \"current_rank\", \"country\"],\n",
    "    output_name=\"away_team.csv\",\n",
    "    dedup_on=\"match_id\"\n",
    ")\n",
    "\n",
    "build_table(\n",
    "    table_keyword=\"tournament_\",\n",
    "    needed_cols=[\"match_id\", \"tournament_id\", \"tournament_name\", \"ground_type\", \"tennis_points\", \"start_datetime\"],\n",
    "    output_name=\"tournament.csv\",\n",
    "    dedup_on=\"match_id\"\n",
    ")\n",
    "\n",
    "build_table(\n",
    "    table_keyword=\"time_\",\n",
    "    needed_cols=[\"match_id\", \"period_1\", \"period_2\", \"period_3\", \"period_4\", \"period_5\", \"current_period_start_timestamp\"],\n",
    "    output_name=\"time.csv\",\n",
    "    dedup_on=\"match_id\"\n",
    ")\n",
    "\n",
    "build_table(\n",
    "    table_keyword=\"statistics_\",\n",
    "    needed_cols=[\"match_id\", \"statistic_name\", \"home_value\", \"away_value\"],\n",
    "    output_name=\"statistics.csv\",\n",
    "    dedup_on=None  # No deduplication because we have multiple rows per match_id in statistics\n",
    ")\n",
    "\n",
    "build_table(\n",
    "    table_keyword=\"power_\",\n",
    "    needed_cols=[\"match_id\", \"set_num\", \"game_num\", \"value\", \"break_occurred\"],\n",
    "    output_name=\"power.csv\",\n",
    "    dedup_on=None # No deduplication because we have multiple rows per match_id in power\n",
    ")\n",
    "\n",
    "build_table(\n",
    "    table_keyword=\"pbp_\",\n",
    "    needed_cols=[\"match_id\", \"set_id\", \"game_id\", \"point_id\", \"home_point\", \"away_point\"],\n",
    "    output_name=\"pbp.csv\",\n",
    "    dedup_on=None # No deduplication because we have multiple rows per match_id in pbp\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86c318f",
   "metadata": {},
   "source": [
    "\n",
    "##  Part 4: Data Cleaning Stage\n",
    "#### In this section, we will clean the extracted CSV files created in the previous section.\n",
    "# \n",
    "### **Goal:**  \n",
    "- Remove duplicate rows  \n",
    " - Handle missing values (`NaN`)  \n",
    " - Standardize data types  \n",
    " The cleaned outputs will be stored in `../data/clean` for the next normalization phase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2153ce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0290f4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "base_path = \"./data/processed\"\n",
    "clean_path = \"./data/clean\"\n",
    "os.makedirs(clean_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be621e6",
   "metadata": {},
   "source": [
    "###  Cleaning: Event Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5140d8b9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d51d825",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/processed/event.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_event = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mevent.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m df_event.drop_duplicates(inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m df_event.columns:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Daneshkar/tennis project/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Daneshkar/tennis project/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Daneshkar/tennis project/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Daneshkar/tennis project/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Daneshkar/tennis project/.venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './data/processed/event.csv'"
     ]
    }
   ],
   "source": [
    "df_event = pd.read_csv(os.path.join(base_path, \"event.csv\"))\n",
    "df_event.drop_duplicates(inplace=True)\n",
    "\n",
    "for col in df_event.columns:\n",
    "    if df_event[col].dtype == 'object':\n",
    "        df_event[col] = df_event[col].fillna(\"Unknown\")\n",
    "    else:\n",
    "        df_event[col] = df_event[col].fillna(0)\n",
    "\n",
    "if \"match_id\" in df_event.columns:\n",
    "    df_event[\"match_id\"] = df_event[\"match_id\"].astype(str)\n",
    "\n",
    "df_event.to_csv(os.path.join(clean_path, \"event_clean.csv\"), index=False)\n",
    "print(\"âœ… event_clean.csv created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2befa5c5",
   "metadata": {},
   "source": [
    "###  Cleaning: Home Team Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80cd1c13",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/processed/home_team.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_home = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhome_team.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m df_home = df_home.drop_duplicates()\n\u001b[32m      4\u001b[39m string_cols = [\u001b[33m\"\u001b[39m\u001b[33mfull_name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgender\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mplays\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcountry\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Daneshkar/tennis project/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Daneshkar/tennis project/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Daneshkar/tennis project/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Daneshkar/tennis project/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Daneshkar/tennis project/.venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './data/processed/home_team.csv'"
     ]
    }
   ],
   "source": [
    "df_home = pd.read_csv(os.path.join(base_path, \"home_team.csv\"))\n",
    "df_home = df_home.drop_duplicates()\n",
    "\n",
    "string_cols = [\"full_name\", \"gender\", \"plays\", \"country\"]\n",
    "numeric_cols = [\"height\", \"weight\", \"current_rank\"]\n",
    "\n",
    "for col in string_cols:\n",
    "    if col in df_home.columns:\n",
    "        df_home[col] = df_home[col].fillna(\"Unknown\")\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col in df_home.columns:\n",
    "        df_home[col] = df_home[col].fillna(0)\n",
    "\n",
    "if \"match_id\" in df_home.columns:\n",
    "    df_home[\"match_id\"] = df_home[\"match_id\"].astype(str)\n",
    "\n",
    "df_home.to_csv(os.path.join(clean_path, \"home_team_clean.csv\"), index=False)\n",
    "print(\"âœ… home_team_clean.csv created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1792e4",
   "metadata": {},
   "source": [
    "###  Cleaning: Away Team Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5cbd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_away = pd.read_csv(os.path.join(base_path, \"away_team.csv\"))\n",
    "df_away = df_away.drop_duplicates()\n",
    "\n",
    "string_cols = [\"full_name\", \"gender\", \"plays\", \"country\"]\n",
    "numeric_cols = [\"height\", \"weight\", \"current_rank\"]\n",
    "\n",
    "for col in string_cols:\n",
    "    if col in df_away.columns:\n",
    "        df_away[col] = df_away[col].fillna(\"Unknown\")\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col in df_away.columns:\n",
    "        df_away[col] = df_away[col].fillna(0)\n",
    "\n",
    "if \"match_id\" in df_away.columns:\n",
    "    df_away[\"match_id\"] = df_away[\"match_id\"].astype(str)\n",
    "\n",
    "df_away.to_csv(os.path.join(clean_path, \"away_team_clean.csv\"), index=False)\n",
    "print(\"âœ… away_team_clean.csv created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04ecbe6",
   "metadata": {},
   "source": [
    "## Part 5: Normalization Stage\n",
    "#### Now that we have clean CSVs, in this part we will:\n",
    "#\n",
    " - Convert data types (e.g., timestamps to datetime)  \n",
    " - Standardize text (e.g., capitalization, spacing)  \n",
    " - Fill remaining missing values intelligently (using mean, median, or mode)  \n",
    " The normalized final datasets will be saved in `../data/clean` as `_final.csv` files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b4cf2c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d5ff054",
   "metadata": {},
   "source": [
    "###  Normalization â€” Event Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d99514a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/clean/event_clean.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m input_path = os.path.join(base_path, \u001b[33m\"\u001b[39m\u001b[33mevent_clean.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m output_path = os.path.join(base_path, \u001b[33m\"\u001b[39m\u001b[33mevent_final.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m df_event = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m df_event[\u001b[33m\"\u001b[39m\u001b[33mmatch_id\u001b[39m\u001b[33m\"\u001b[39m] = df_event[\u001b[33m\"\u001b[39m\u001b[33mmatch_id\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m      8\u001b[39m df_event[\u001b[33m\"\u001b[39m\u001b[33mdefault_period_count\u001b[39m\u001b[33m\"\u001b[39m] = df_event[\u001b[33m\"\u001b[39m\u001b[33mdefault_period_count\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Daneshkar/tennis project/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Daneshkar/tennis project/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Daneshkar/tennis project/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Daneshkar/tennis project/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Daneshkar/tennis project/.venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './data/clean/event_clean.csv'"
     ]
    }
   ],
   "source": [
    "base_path = \"./data/clean\"\n",
    "input_path = os.path.join(base_path, \"event_clean.csv\")\n",
    "output_path = os.path.join(base_path, \"event_final.csv\")\n",
    "\n",
    "df_event = pd.read_csv(input_path)\n",
    "\n",
    "df_event[\"match_id\"] = df_event[\"match_id\"].astype(int)\n",
    "df_event[\"default_period_count\"] = df_event[\"default_period_count\"].astype(int)\n",
    "df_event[\"date_source\"] = df_event[\"date_source\"].astype(int)\n",
    "\n",
    "if np.issubdtype(df_event[\"start_datetime\"].dtype, np.number):\n",
    "    df_event[\"start_datetime\"] = pd.to_datetime(df_event[\"start_datetime\"], unit=\"s\", errors=\"coerce\")\n",
    "\n",
    "df_event[\"winner_code\"] = df_event[\"winner_code\"].fillna(df_event[\"winner_code\"].mode()[0])\n",
    "df_event[\"first_to_serve\"] = df_event[\"first_to_serve\"].fillna(df_event[\"first_to_serve\"].mode()[0])\n",
    "\n",
    "df_event.to_csv(output_path, index=False)\n",
    "print(\"âœ… event_final.csv created successfully!\")\n",
    "print(df_event.info())\n",
    "print(df_event.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db57c37",
   "metadata": {},
   "source": [
    "###  Normalization â€” Home Team Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2dc1f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/clean/home_team_clean.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m input_path = os.path.join(base_path, \u001b[33m\"\u001b[39m\u001b[33mhome_team_clean.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m output_path = os.path.join(base_path, \u001b[33m\"\u001b[39m\u001b[33mhome_team_final.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df_home = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m numeric_cols = [\u001b[33m\"\u001b[39m\u001b[33mheight\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mweight\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcurrent_rank\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m numeric_cols:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Daneshkar/tennis project/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Daneshkar/tennis project/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Daneshkar/tennis project/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Daneshkar/tennis project/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Daneshkar/tennis project/.venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './data/clean/home_team_clean.csv'"
     ]
    }
   ],
   "source": [
    "input_path = os.path.join(base_path, \"home_team_clean.csv\")\n",
    "output_path = os.path.join(base_path, \"home_team_final.csv\")\n",
    "\n",
    "df_home = pd.read_csv(input_path)\n",
    "\n",
    "numeric_cols = [\"height\", \"weight\", \"current_rank\"]\n",
    "for col in numeric_cols:\n",
    "    if col in df_home.columns:\n",
    "        df_home[col] = pd.to_numeric(df_home[col], errors=\"coerce\")\n",
    "\n",
    "if \"gender\" in df_home.columns:\n",
    "    df_home[\"gender\"] = df_home[\"gender\"].astype(str).str.strip().str.title().replace({\"Nan\":\"Unknown\"})\n",
    "if \"plays\" in df_home.columns:\n",
    "    df_home[\"plays\"] = df_home[\"plays\"].astype(str).str.strip().str.lower().replace({\"nan\":\"unknown\"})\n",
    "for col in [\"full_name\", \"country\"]:\n",
    "    if col in df_home.columns:\n",
    "        df_home[col] = df_home[col].astype(str).str.strip()\n",
    "\n",
    "if \"height\" in df_home.columns:\n",
    "    df_home[\"height\"] = df_home[\"height\"].fillna(df_home[\"height\"].mean(skipna=True))\n",
    "if \"weight\" in df_home.columns:\n",
    "    df_home[\"weight\"] = df_home[\"weight\"].fillna(df_home[\"weight\"].mean(skipna=True))\n",
    "if \"current_rank\" in df_home.columns:\n",
    "    df_home[\"current_rank\"] = df_home[\"current_rank\"].fillna(df_home[\"current_rank\"].median(skipna=True))\n",
    "\n",
    "for col in [\"gender\", \"plays\"]:\n",
    "    if col in df_home.columns:\n",
    "        mode_val = df_home[col].mode(dropna=True)\n",
    "        if not mode_val.empty:\n",
    "            df_home[col] = df_home[col].fillna(mode_val.iloc[0])\n",
    "        else:\n",
    "            df_home[col] = df_home[col].fillna(\"Unknown\")\n",
    "\n",
    "for col in [\"player_id\", \"full_name\", \"country\"]:\n",
    "    if col in df_home.columns:\n",
    "        df_home[col] = df_home[col].fillna(\"Unknown\")\n",
    "\n",
    "if \"match_id\" in df_home.columns:\n",
    "    df_home[\"match_id\"] = df_home[\"match_id\"].astype(str)\n",
    "\n",
    "df_home.to_csv(output_path, index=False)\n",
    "print(\"âœ… home_team_final.csv created successfully!\")\n",
    "print(df_home.info())\n",
    "print(df_home.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85590ad4",
   "metadata": {},
   "source": [
    "###  Normalization â€” Away Team Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa77dd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = os.path.join(base_path, \"away_team_clean.csv\")\n",
    "output_path = os.path.join(base_path, \"away_team_final.csv\")\n",
    "\n",
    "df_away = pd.read_csv(input_path)\n",
    "\n",
    "numeric_cols = [\"height\", \"weight\", \"current_rank\"]\n",
    "for col in numeric_cols:\n",
    "    if col in df_away.columns:\n",
    "        df_away[col] = pd.to_numeric(df_away[col], errors=\"coerce\")\n",
    "\n",
    "if \"gender\" in df_away.columns:\n",
    "    df_away[\"gender\"] = df_away[\"gender\"].astype(str).str.strip().str.title().replace({\"Nan\":\"Unknown\"})\n",
    "if \"plays\" in df_away.columns:\n",
    "    df_away[\"plays\"] = df_away[\"plays\"].astype(str).str.strip().str.lower().replace({\"nan\":\"unknown\"})\n",
    "for col in [\"full_name\", \"country\"]:\n",
    "    if col in df_away.columns:\n",
    "        df_away[col] = df_away[col].astype(str).str.strip()\n",
    "\n",
    "if \"height\" in df_away.columns:\n",
    "    df_away[\"height\"] = df_away[\"height\"].fillna(df_away[\"height\"].mean(skipna=True))\n",
    "if \"weight\" in df_away.columns:\n",
    "    df_away[\"weight\"] = df_away[\"weight\"].fillna(df_away[\"weight\"].mean(skipna=True))\n",
    "if \"current_rank\" in df_away.columns:\n",
    "    df_away[\"current_rank\"] = df_away[\"current_rank\"].fillna(df_away[\"current_rank\"].median(skipna=True))\n",
    "\n",
    "for col in [\"gender\", \"plays\"]:\n",
    "    if col in df_away.columns:\n",
    "        mode_val = df_away[col].mode(dropna=True)\n",
    "        if not mode_val.empty:\n",
    "            df_away[col] = df_away[col].fillna(mode_val.iloc[0])\n",
    "        else:\n",
    "            df_away[col] = df_away[col].fillna(\"Unknown\")\n",
    "\n",
    "for col in [\"player_id\", \"full_name\", \"country\"]:\n",
    "    if col in df_away.columns:\n",
    "        df_away[col] = df_away[col].fillna(\"Unknown\")\n",
    "\n",
    "if \"match_id\" in df_away.columns:\n",
    "    df_away[\"match_id\"] = df_away[\"match_id\"].astype(str)\n",
    "\n",
    "df_away.to_csv(output_path, index=False)\n",
    "print(\"âœ… away_team_final.csv created successfully!\")\n",
    "print(df_away.info())\n",
    "print(df_away.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7009e14",
   "metadata": {},
   "source": [
    "##  Part 6: Review and Summary\n",
    "#### In this final part, we review all steps in the data preparation phase:\n",
    "# \n",
    "| Step | Description | Output Folder | Key Action |\n",
    "|------|--------------|----------------|-------------|\n",
    "| 1 | Extraction from Parquet (Raw) | `../data/processed` | `build_table()` function |\n",
    "| 2 | Cleaning | `../data/clean` | Remove duplicates, fill NaN with neutral values |\n",
    "| 3 | Normalization | `../data/clean` | Type casting, smart imputation |\n",
    "# \n",
    "####  All datasets are now ready for **Phase 2 (Data Integration)**, where we will merge and build the central match table for analysis.\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33b276b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
